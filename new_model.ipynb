{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18725,
     "status": "ok",
     "timestamp": 1764599453647,
     "user": {
      "displayName": "Semen Pobrodilin",
      "userId": "06118903328537142306"
     },
     "user_tz": -60
    },
    "id": "5BGJMJe9RiiU"
   },
   "outputs": [],
   "source": [
    "from dataset.translate import *\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, precision_score, f1_score\n",
    "import wandb\n",
    "import kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"alessiocorrado99/animals10\")\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1764599453661,
     "user": {
      "displayName": "Semen Pobrodilin",
      "userId": "06118903328537142306"
     },
     "user_tz": -60
    },
    "id": "dRhEXGwvRlhE"
   },
   "outputs": [],
   "source": [
    "def translate_label(dirname: str, mapping: dict[str, str]) -> str:\n",
    "    translated = mapping.get(dirname, dirname)\n",
    "    return translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 27456,
     "status": "ok",
     "timestamp": 1764599481119,
     "user": {
      "displayName": "Semen Pobrodilin",
      "userId": "06118903328537142306"
     },
     "user_tz": -60
    },
    "id": "4mbbbEmORzG4"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "data = []\n",
    "\n",
    "for (dirpath, dirnames, filenames) in os.walk(path + \"/raw-img\"):\n",
    "    if filenames:\n",
    "        label = os.path.basename(dirpath)\n",
    "        translated_label = translate_label(label, translate_it_to_en)\n",
    "        for filename in filenames:\n",
    "            filepath = os.path.join(dirpath, filename)\n",
    "            data.append({'label': translated_label, 'filepath': filepath})\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1764599481180,
     "user": {
      "displayName": "Semen Pobrodilin",
      "userId": "06118903328537142306"
     },
     "user_tz": -60
    },
    "id": "_0lwNiyXR065",
    "outputId": "f8ef0e99-d3a2-4bcc-aefb-b89d0310097c"
   },
   "outputs": [],
   "source": [
    "labelEncoding = {label: str(idx) for idx, label in enumerate(df['label'].unique())}\n",
    "df['label_encoded'] = df['label'].map(labelEncoding)\n",
    "df.groupby('label_encoded').first().head(df['label'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1764599481192,
     "user": {
      "displayName": "Semen Pobrodilin",
      "userId": "06118903328537142306"
     },
     "user_tz": -60
    },
    "id": "UKY6Ce44R4t6"
   },
   "outputs": [],
   "source": [
    "def split_data(df: pd.DataFrame, test_size: float, val_size: float, random_state: int):\n",
    "    train_val_df, test_df = train_test_split(\n",
    "        df,\n",
    "        test_size=test_size,\n",
    "        stratify=df['label_encoded'],\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    val_relative_size = val_size / (1 - test_size)\n",
    "\n",
    "    train_df, val_df = train_test_split(\n",
    "        train_val_df,\n",
    "        test_size=val_relative_size,\n",
    "        stratify=train_val_df['label_encoded'],\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    train_x = train_df['filepath']\n",
    "    train_y = train_df['label_encoded']\n",
    "\n",
    "    val_x = val_df['filepath']\n",
    "    val_y = val_df['label_encoded']\n",
    "\n",
    "    test_x = test_df['filepath']\n",
    "    test_y = test_df['label_encoded']\n",
    "\n",
    "    return train_x, train_y, val_x, val_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1764599481246,
     "user": {
      "displayName": "Semen Pobrodilin",
      "userId": "06118903328537142306"
     },
     "user_tz": -60
    },
    "id": "SoyAeW1RR7-R"
   },
   "outputs": [],
   "source": [
    "train_x, train_y, val_x, val_y, test_x, test_y = split_data(df, test_size=0.2, val_size=0.1, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1297,
     "status": "ok",
     "timestamp": 1764599482553,
     "user": {
      "displayName": "Semen Pobrodilin",
      "userId": "06118903328537142306"
     },
     "user_tz": -60
    },
    "id": "ktVIDltrSfGM"
   },
   "outputs": [],
   "source": [
    "from image_dataset import ImageDataset\n",
    "tr = transforms.Compose([\n",
    "    transforms.Resize(size=(128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = ImageDataset(val_x, val_y, transform=tr)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "test_dataset = ImageDataset(test_x, test_y, transform=tr)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1764599482574,
     "user": {
      "displayName": "Semen Pobrodilin",
      "userId": "06118903328537142306"
     },
     "user_tz": -60
    },
    "id": "DO-KUHiPSm0M",
    "outputId": "7c8199d0-0175-4982-f1b9-8813d9ef1a32"
   },
   "outputs": [],
   "source": [
    "device = torch.device(device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1764599504269,
     "user": {
      "displayName": "Semen Pobrodilin",
      "userId": "06118903328537142306"
     },
     "user_tz": -60
    },
    "id": "4eT7u6xmThH_"
   },
   "outputs": [],
   "source": [
    "class baseCNN(nn.Module):\n",
    "    def __init__(self, num_classes, conv_dropouts=None, linear_dropout=0.2, filters=None):\n",
    "        super().__init__()\n",
    "\n",
    "        # Default architecture\n",
    "        if filters is None:\n",
    "            filters = [32, 128, 256, 512]\n",
    "        if conv_dropouts is None:\n",
    "            conv_dropouts = [0.2, 0.2, 0.2, 0.25]\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            self.conv_block(3, filters[0], conv_dropouts[0]),\n",
    "            self.conv_block(filters[0], filters[1], conv_dropouts[1]),\n",
    "            self.conv_block(filters[1], filters[2], conv_dropouts[2]),\n",
    "            self.conv_block(filters[2], filters[3], conv_dropouts[3]),\n",
    "\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(filters[3], 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(linear_dropout),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def conv_block(self, in_chanel, out_chanel, drop):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_chanel, out_chanel, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_chanel),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(out_chanel, out_chanel, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_chanel),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(3),  # Note: using 3 instead of 2\n",
    "            nn.Dropout(drop)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def train_epoch(self, dataloader: DataLoader, criterion: nn.Module, optimizer: torch.optim.Optimizer, device: str):\n",
    "        self.train()\n",
    "        total_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for features, targets in dataloader:\n",
    "            features, targets = features.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = self(features)\n",
    "            loss = criterion(logits, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_size = targets.size(0)\n",
    "            total_loss += loss.item() * batch_size\n",
    "            preds = logits.argmax(dim=1)\n",
    "            total_correct += (preds == targets).sum().item()\n",
    "            total += batch_size\n",
    "\n",
    "        return total_loss / total, total_correct / total\n",
    "\n",
    "\n",
    "    def evaluate(self, dataloader: DataLoader, criterion: nn.Module, device: str):\n",
    "        self.eval()\n",
    "        total_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for features, targets in dataloader:\n",
    "                features, targets = features.to(device), targets.to(device)\n",
    "\n",
    "                logits = self(features)\n",
    "                loss = criterion(logits, targets)\n",
    "\n",
    "                batch_size = targets.size(0)\n",
    "                total_loss += loss.item() * batch_size\n",
    "                preds = logits.argmax(dim=1)\n",
    "                total_correct += (preds == targets).sum().item()\n",
    "                total += batch_size\n",
    "\n",
    "        return total_loss / total, total_correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1764599505928,
     "user": {
      "displayName": "Semen Pobrodilin",
      "userId": "06118903328537142306"
     },
     "user_tz": -60
    },
    "id": "jah7Die_Tjfj"
   },
   "outputs": [],
   "source": [
    "# def train(run: wandb.Run, model: nn.Module, optimizer: torch.optim.Optimizer, criterion: nn.Module, train_loader: DataLoader, num_epochs=8):\n",
    "#     loss_vals=  []\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         running_loss = 0.0\n",
    "#         correct = 0\n",
    "#         total = 0\n",
    "\n",
    "#         epoch_loss= []\n",
    "#         for _, (data, targets) in enumerate(train_loader):\n",
    "#             data = data.to(device=device)\n",
    "#             targets = targets.to(device=device)\n",
    "\n",
    "#             scores = model(data)\n",
    "#             loss = criterion(scores, targets)\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             running_loss += loss.item()\n",
    "#             _, predicted = scores.max(1)\n",
    "#             total += targets.size(0)\n",
    "#             correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "#         epoch_loss = running_loss / len(train_loader)\n",
    "#         epoch_acc = 100. * correct / total\n",
    "#         loss_vals.append(epoch_loss)\n",
    "#         run.log({\"Train Loss\": epoch_loss, \"Train Accuracy\": epoch_acc, \"epoch\": epoch})\n",
    "\n",
    "#         print(epoch, \"Current Loss:\", loss , \"Acc:\" , epoch_acc )\n",
    "#     return loss_vals\n",
    "\n",
    "# def evaluate(loader, model):\n",
    "#     \"\"\"\n",
    "#         @returns: (all_preds, all_targets)\n",
    "#     \"\"\"\n",
    "#     all_preds = []\n",
    "#     all_targets = []\n",
    "#     running_loss = 0.0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "\n",
    "#     model.eval()\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for x, y in loader:\n",
    "#             x = x.to(device=device)\n",
    "#             y = y.to(device=device)\n",
    "\n",
    "#             scores = model(x)\n",
    "#             loss = criterion(scores, y)\n",
    "#             _, pred = scores.max(1)\n",
    "\n",
    "#             all_preds.extend(pred.cpu().numpy())\n",
    "#             all_targets.extend(y.cpu().numpy())\n",
    "\n",
    "#             running_loss += loss.item()\n",
    "#             total += y.size(0)\n",
    "#             correct += pred.eq(y).sum().item()\n",
    "\n",
    "#     accuracy = 100. * correct / total\n",
    "#     avg_loss = running_loss / len(loader)\n",
    "\n",
    "#     return all_preds, all_targets, accuracy, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1764599509728,
     "user": {
      "displayName": "Semen Pobrodilin",
      "userId": "06118903328537142306"
     },
     "user_tz": -60
    },
    "id": "XMgNAx_aTmFb"
   },
   "outputs": [],
   "source": [
    "def train_with_config(run: wandb.Run, config, train_loader, val_loader, device, num_classes=10,):\n",
    "\n",
    "    model = baseCNN(\n",
    "        num_classes=num_classes,\n",
    "        conv_dropouts=config.get('conv_dropouts', [0.2, 0.2, 0.2, 0.25]),\n",
    "        linear_dropout=config.get('linear_dropout', 0.2)\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_state = None\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(config.epochs):\n",
    "\n",
    "        train_loss, train_acc = model.train_epoch( train_loader, criterion, optimizer, device)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss, val_acc = model.evaluate( val_loader, criterion, device)\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "        run.log({\"epoch\": epoch + 1, \"train_loss\": train_loss, \"val_loss\": val_loss, \"val_accuracy\": val_acc, \"train_accuracy\": train_acc})\n",
    "\n",
    "    assert best_state is not None\n",
    "\n",
    "    return best_state, best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1764599511214,
     "user": {
      "displayName": "Semen Pobrodilin",
      "userId": "06118903328537142306"
     },
     "user_tz": -60
    },
    "id": "YthntYP6ToGq"
   },
   "outputs": [],
   "source": [
    "configs = [\n",
    "    # {'lr': 0.001, 'conv_dropouts': [0.2, 0.2, 0.2, 0.25], 'linear_dropout': 0.2},\n",
    "    {'lr': 0.0005, 'conv_dropouts': [0.2, 0.2, 0.2, 0.25], 'linear_dropout': 0.2},\n",
    "\n",
    "    # {'lr': 0.001, 'conv_dropouts': [0.1, 0.1, 0.15, 0.2], 'linear_dropout': 0.1},\n",
    "    {'lr': 0.001, 'conv_dropouts': [0.3, 0.3, 0.35, 0.4], 'linear_dropout': 0.3},\n",
    "\n",
    "    {'lr': 0.001, 'filters': [32, 64, 128, 256]},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_API_KEY'] = \"71c92645b7421a14f584454ecb6d69f570710ec1\"\n",
    "api_key = os.environ.get('WANDB_API_KEY')\n",
    "if api_key:\n",
    "    wandb.login(key=api_key)\n",
    "    print(\"Logged in to W&B successfully.\")\n",
    "else:\n",
    "    raise ValueError(\"W&B API key not found in environment variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1611971,
     "status": "ok",
     "timestamp": 1764601124356,
     "user": {
      "displayName": "Semen Pobrodilin",
      "userId": "06118903328537142306"
     },
     "user_tz": -60
    },
    "id": "Cg2GRibZTqPu",
    "outputId": "4dfda384-1000-4f80-d170-48a441680493"
   },
   "outputs": [],
   "source": [
    "run = wandb.init(project=\"animal_classification\", name=\"test_hyperparam\")\n",
    "best_state = None\n",
    "best_val_loss = float('inf')\n",
    "best_config = None\n",
    "\n",
    "for i, config in enumerate(configs):\n",
    "    best_state, best_val_loss = train_with_config(run, config, train_loader, test_loader, device)\n",
    "    if best_val_loss < best_val_loss:\n",
    "        best_val_loss = best_val_loss\n",
    "        best_config = config\n",
    "    \n",
    "run.finish()\n",
    "print(\"Training complete.\")\n",
    "print(f\"Best validation loss: {best_val_loss} for model with config: {best_config}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
